{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"seminar.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"so7K8OQN0igQ"},"source":["## Seminar 1: Fun with Word Embeddings (3 points)\n","\n","Today we gonna play with word embeddings: train our own little embedding, load one from   gensim model zoo and use it to visualize text corpora.\n","\n","This whole thing is gonna happen on top of embedding dataset.\n","\n","__Requirements:__  `pip install --upgrade nltk gensim bokeh` , but only if you're running locally."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":969},"id":"vUim36mB0q2_","executionInfo":{"status":"ok","timestamp":1611834585617,"user_tz":-180,"elapsed":24136,"user":{"displayName":"Aleksey Shimko","photoUrl":"","userId":"06639583344500545085"}},"outputId":"d0783eeb-bafc-49c8-bc01-58f123e58520"},"source":["pip install --upgrade nltk gensim bokeh"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting nltk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 6.6MB/s \n","\u001b[?25hCollecting gensim\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n","\u001b[K     |████████████████████████████████| 24.2MB 1.5MB/s \n","\u001b[?25hCollecting bokeh\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/20/f67d851da06f0f9358ae4e62296e76fefafaa1a5991f1c69496a83ee09ab/bokeh-2.2.3.tar.gz (8.8MB)\n","\u001b[K     |████████████████████████████████| 8.9MB 55.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (1.0.0)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.41.1)\n","Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.2)\n","Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n","Requirement already satisfied, skipping upgrade: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.13)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.8.1)\n","Requirement already satisfied, skipping upgrade: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.11.2)\n","Collecting pillow>=7.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c0/442d9d87e0da00bf856ef6dd4916f84a2d710b5f1a367d42d7f3c4e99a6c/Pillow-8.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 53.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh) (20.8)\n","Requirement already satisfied, skipping upgrade: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (5.1.1)\n","Requirement already satisfied, skipping upgrade: typing_extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=16.8->bokeh) (2.4.7)\n","Building wheels for collected packages: nltk, bokeh\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=5dfc87d9337b7e839d7a778952000bf80ef8824c2f8cf052e82e2b3fa28da1cf\n","  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n","  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bokeh: filename=bokeh-2.2.3-cp36-none-any.whl size=9296311 sha256=1b8e1b20bb402d0622ba83cbc650943a2494e8114637cfef8f2f5bb5099551e7\n","  Stored in directory: /root/.cache/pip/wheels/dc/96/7b/9c9d48ed392511bc708e39580e18dc7a92f475795cd26b51bf\n","Successfully built nltk bokeh\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: nltk, gensim, pillow, bokeh\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","  Found existing installation: bokeh 2.1.1\n","    Uninstalling bokeh-2.1.1:\n","      Successfully uninstalled bokeh-2.1.1\n","Successfully installed bokeh-2.2.3 gensim-3.8.3 nltk-3.5 pillow-8.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"K_Tbvc_y0igX","executionInfo":{"status":"ok","timestamp":1611834601168,"user_tz":-180,"elapsed":2468,"user":{"displayName":"Aleksey Shimko","photoUrl":"","userId":"06639583344500545085"}},"outputId":"348ef94f-fbe6-4572-c58e-b3d7fa3d59d4"},"source":["# download the data:\n","!wget https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1 -O ./quora.txt\n","# alternative download link: https://yadi.sk/i/BPQrUu1NaTduEw"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-01-28 11:49:59--  https://www.dropbox.com/s/obaitrix9jyu84r/quora.txt?dl=1\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/dl/obaitrix9jyu84r/quora.txt [following]\n","--2021-01-28 11:49:59--  https://www.dropbox.com/s/dl/obaitrix9jyu84r/quora.txt\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc80b417b9258a0e2ea128a551d1.dl.dropboxusercontent.com/cd/0/get/BH1i7ygZBSiOpwTRNj_G6a7Fto_Jn8KlMqSz1kTs_YPYS8hd2xrNRLxhRiW_MPIKlM1I_hEB52nviPqILlPckLu76Ymjqp1ha-jNuUd6GZRp7A/file?dl=1# [following]\n","--2021-01-28 11:49:59--  https://uc80b417b9258a0e2ea128a551d1.dl.dropboxusercontent.com/cd/0/get/BH1i7ygZBSiOpwTRNj_G6a7Fto_Jn8KlMqSz1kTs_YPYS8hd2xrNRLxhRiW_MPIKlM1I_hEB52nviPqILlPckLu76Ymjqp1ha-jNuUd6GZRp7A/file?dl=1\n","Resolving uc80b417b9258a0e2ea128a551d1.dl.dropboxusercontent.com (uc80b417b9258a0e2ea128a551d1.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601b:15::a27d:80f\n","Connecting to uc80b417b9258a0e2ea128a551d1.dl.dropboxusercontent.com (uc80b417b9258a0e2ea128a551d1.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 33813903 (32M) [application/binary]\n","Saving to: ‘./quora.txt’\n","\n","./quora.txt         100%[===================>]  32.25M  71.8MB/s    in 0.4s    \n","\n","2021-01-28 11:50:00 (71.8 MB/s) - ‘./quora.txt’ saved [33813903/33813903]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"kRyquC4T0igY","executionInfo":{"status":"ok","timestamp":1611834603675,"user_tz":-180,"elapsed":678,"user":{"displayName":"Aleksey Shimko","photoUrl":"","userId":"06639583344500545085"}},"outputId":"a54f3085-f623-4994-c614-58150d36a8d0"},"source":["import numpy as np\n","\n","data = list(open(\"./quora.txt\", encoding=\"utf-8\"))\n","data[50]"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"What TV shows or books help you read people's body language?\\n\""]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"z3nMC3510igY"},"source":["__Tokenization:__ a typical first step for an nlp task is to split raw data into words.\n","The text we're working with is in raw format: with all the punctuation and smiles attached to some words, so a simple str.split won't do.\n","\n","Let's use __`nltk`__ - a library that handles many nlp tasks like tokenization, stemming or part-of-speech tagging."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-cAX-kS0igZ","executionInfo":{"status":"ok","timestamp":1611834760652,"user_tz":-180,"elapsed":2065,"user":{"displayName":"Aleksey Shimko","photoUrl":"","userId":"06639583344500545085"}},"outputId":"4b7aa4c0-ecd8-45fc-eea2-906a216e7660"},"source":["from nltk.tokenize import WordPunctTokenizer\n","tokenizer = WordPunctTokenizer()\n","\n","print(tokenizer.tokenize(data[50]))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["['What', 'TV', 'shows', 'or', 'books', 'help', 'you', 'read', 'people', \"'\", 's', 'body', 'language', '?']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"zE8Eqn3T0igZ"},"source":["# TASK: lowercase everything and extract tokens with tokenizer. \n","# data_tok should be a list of lists of tokens for each line in data.\n","\n","data_tok = # YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"mz3_q10-0igZ"},"source":["assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n","assert all(all(isinstance(tok, str) for tok in row) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n","is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n","assert all(map(lambda l: not is_latin(l) or l.islower(), map(' '.join, data_tok))), \"please make sure to lowercase the data\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTw502ea0iga"},"source":["print([' '.join(row) for row in data_tok[:2]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XsLOhVsb0iga"},"source":["__Word vectors:__ as the saying goes, there's more than one way to train word embeddings. There's Word2Vec and GloVe with different objective functions. Then there's fasttext that uses character-level models to train word embeddings. \n","\n","The choice is huge, so let's start someplace small: __gensim__ is another nlp library that features many vector-based models incuding word2vec."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"0M0qI9KV0iga"},"source":["from gensim.models import Word2Vec\n","model = Word2Vec(data_tok, \n","                 size=32,      # embedding vector size\n","                 min_count=5,  # consider words that occured at least 5 times\n","                 window=5).wv  # define context as a 5-word window around the target word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"visl71MF0igb"},"source":["# now you can get word vectors !\n","model.get_vector('anything')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_490aX1m0igb"},"source":["# or query similar words directly. Go play with it!\n","model.most_similar('bread')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ix_ANerV0igb"},"source":["### Using pre-trained model\n","\n","Took it a while, huh? Now imagine training life-sized (100~300D) word embeddings on gigabytes of text: wikipedia articles or twitter posts. \n","\n","Thankfully, nowadays you can get a pre-trained word embedding model in 2 lines of code (no sms required, promise)."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"db5-yPXq0igb"},"source":["import gensim.downloader as api\n","model = api.load('glove-twitter-100')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRE28jCn0igc"},"source":["model.most_similar(positive=[\"coder\", \"money\"], negative=[\"brain\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6F6JeLIy0igc"},"source":["### Visualizing word vectors\n","\n","One way to see if our vectors are any good is to plot them. Thing is, those vectors are in 30D+ space and we humans are more used to 2-3D.\n","\n","Luckily, we machine learners know about __dimensionality reduction__ methods.\n","\n","Let's use that to plot 1000 most frequent words"]},{"cell_type":"code","metadata":{"id":"wNmvpIWA0igc"},"source":["words = sorted(model.vocab.keys(), \n","               key=lambda word: model.vocab[word].count,\n","               reverse=True)[:1000]\n","\n","print(words[::100])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KlH3O8e0igc"},"source":["# for each word, compute it's vector with model\n","word_vectors = # YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"cpxPHDvx0igc"},"source":["assert isinstance(word_vectors, np.ndarray)\n","assert word_vectors.shape == (len(words), 100)\n","assert np.isfinite(word_vectors).all()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jKS9dZ9m0igd"},"source":["#### Linear projection: PCA\n","\n","The simplest linear dimensionality reduction method is __P__rincipial __C__omponent __A__nalysis.\n","\n","In geometric terms, PCA tries to find axes along which most of the variance occurs. The \"natural\" axes, if you wish.\n","\n","<img src=\"https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/pca_fish.png\" style=\"width:30%\">\n","\n","\n","Under the hood, it attempts to decompose object-feature matrix $X$ into two smaller matrices: $W$ and $\\hat W$ minimizing _mean squared error_:\n","\n","$$\\|(X W) \\hat{W} - X\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n","- $X \\in \\mathbb{R}^{n \\times m}$ - object matrix (**centered**);\n","- $W \\in \\mathbb{R}^{m \\times d}$ - matrix of direct transformation;\n","- $\\hat{W} \\in \\mathbb{R}^{d \\times m}$ - matrix of reverse transformation;\n","- $n$ samples, $m$ original dimensions and $d$ target dimensions;\n","\n"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"yHCOmJkV0igd"},"source":["from sklearn.decomposition import PCA\n","\n","# map word vectors onto 2d plane with PCA. Use good old sklearn api (fit, transform)\n","# after that, normalize vectors to make sure they have zero mean and unit variance\n","word_vectors_pca = # YOUR CODE\n","\n","# and maybe MORE OF YOUR CODE here :)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"fwyEt2N40igd"},"source":["assert word_vectors_pca.shape == (len(word_vectors), 2), \"there must be a 2d vector for each word\"\n","assert max(abs(word_vectors_pca.mean(0))) < 1e-5, \"points must be zero-centered\"\n","assert max(abs(1.0 - word_vectors_pca.std(0))) < 1e-2, \"points must have unit variance\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VJQ44jVz0ige"},"source":["#### Let's draw it!"]},{"cell_type":"code","metadata":{"id":"sZJAzpg_0ige"},"source":["import bokeh.models as bm, bokeh.plotting as pl\n","from bokeh.io import output_notebook\n","output_notebook()\n","\n","def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n","                 width=600, height=400, show=True, **kwargs):\n","    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n","    if isinstance(color, str): color = [color] * len(x)\n","    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n","\n","    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n","    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n","\n","    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n","    if show: pl.show(fig)\n","    return fig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xafj1Ru20ige"},"source":["draw_vectors(word_vectors_pca[:, 0], word_vectors_pca[:, 1], token=words)\n","\n","# hover a mouse over there and see if you can identify the clusters"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ziEGGV30igf"},"source":["### Visualizing neighbors with t-SNE\n","PCA is nice but it's strictly linear and thus only able to capture coarse high-level structure of the data.\n","\n","If we instead want to focus on keeping neighboring points near, we could use TSNE, which is itself an embedding method. Here you can read __[more on TSNE](https://distill.pub/2016/misread-tsne/)__."]},{"cell_type":"code","metadata":{"id":"3sM96Z3J0igf"},"source":["from sklearn.manifold import TSNE\n","\n","# map word vectors onto 2d plane with TSNE. hint: don't panic it may take a minute or two to fit.\n","# normalize them as just lke with pca\n","\n","\n","word_tsne = #YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"scrolled":false,"id":"KNsGYRqW0igf"},"source":["draw_vectors(word_tsne[:, 0], word_tsne[:, 1], color='green', token=words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zyxo9xGM0igg"},"source":["### Visualizing phrases\n","\n","Word embeddings can also be used to represent short phrases. The simplest way is to take __an average__ of vectors for all tokens in the phrase with some weights.\n","\n","This trick is useful to identify what data are you working with: find if there are any outliers, clusters or other artefacts.\n","\n","Let's try this new hammer on our data!\n"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"8hm3I8mh0igg"},"source":["def get_phrase_embedding(phrase):\n","    \"\"\"\n","    Convert phrase to a vector by aggregating it's word embeddings. See description above.\n","    \"\"\"\n","    # 1. lowercase phrase\n","    # 2. tokenize phrase\n","    # 3. average word vectors for all words in tokenized phrase\n","    # skip words that are not in model's vocabulary\n","    # if all words are missing from vocabulary, return zeros\n","    \n","    vector = np.zeros([model.vector_size], dtype='float32')\n","    \n","    # YOUR CODE\n","    \n","    return vector\n","        \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"P0bW2i0g0igg"},"source":["vector = get_phrase_embedding(\"I'm very sure. This never happened to me before...\")\n","\n","assert np.allclose(vector[::10],\n","                   np.array([ 0.31807372, -0.02558171,  0.0933293 , -0.1002182 , -1.0278689 ,\n","                             -0.16621883,  0.05083408,  0.17989802,  1.3701859 ,  0.08655966],\n","                              dtype=np.float32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"VwMGKTJY0igg"},"source":["# let's only consider ~5k phrases for a first run.\n","chosen_phrases = data[::len(data) // 1000]\n","\n","# compute vectors for chosen phrases\n","phrase_vectors = # YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Dj_61DHP0igg"},"source":["assert isinstance(phrase_vectors, np.ndarray) and np.isfinite(phrase_vectors).all()\n","assert phrase_vectors.shape == (len(chosen_phrases), model.vector_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"SvWYXuts0igh"},"source":["# map vectors into 2d space with pca, tsne or your other method of choice\n","# don't forget to normalize\n","\n","phrase_vectors_2d = TSNE().fit_transform(phrase_vectors)\n","\n","phrase_vectors_2d = (phrase_vectors_2d - phrase_vectors_2d.mean(axis=0)) / phrase_vectors_2d.std(axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"1oebhHs_0igh"},"source":["draw_vectors(phrase_vectors_2d[:, 0], phrase_vectors_2d[:, 1],\n","             phrase=[phrase[:50] for phrase in chosen_phrases],\n","             radius=20,)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RX_YjvA80igh"},"source":["Finally, let's build a simple \"similar question\" engine with phrase embeddings we've built."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"lrPcK8xr0igh"},"source":["# compute vector embedding for all lines in data\n","data_vectors = np.array([get_phrase_embedding(l) for l in data])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"JY6iJaI20igi"},"source":["def find_nearest(query, k=10):\n","    \"\"\"\n","    given text line (query), return k most similar lines from data, sorted from most to least similar\n","    similarity should be measured as cosine between query and line embedding vectors\n","    hint: it's okay to use global variables: data and data_vectors. see also: np.argpartition, np.argsort\n","    \"\"\"\n","    # YOUR CODE\n","    \n","    return <YOUR CODE: top-k lines starting from most similar>"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"b_DjL1_Q0igi"},"source":["results = find_nearest(query=\"How do i enter the matrix?\", k=10)\n","\n","print(''.join(results))\n","\n","assert len(results) == 10 and isinstance(results[0], str)\n","assert results[0] == 'How do I get to the dark web?\\n'\n","assert results[3] == 'What can I do to save the world?\\n'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"nrMyYukx0igi"},"source":["find_nearest(query=\"How does Trump?\", k=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"KbZ86be_0igi"},"source":["find_nearest(query=\"Why don't i ask a question myself?\", k=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"YU7M3EMV0igj"},"source":["__Now what?__\n","* Try running TSNE on all data, not just 1000 phrases\n","* See what other embeddings are there in the model zoo: `gensim.downloader.info()`\n","* Take a look at [FastText](https://github.com/facebookresearch/fastText) embeddings\n","* Optimize find_nearest with locality-sensitive hashing: use [nearpy](https://github.com/pixelogik/NearPy) or `sklearn.neighbors`."]}]}